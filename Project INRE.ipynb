{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyPdf\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def tokenize(path):\n",
    "    # open PDF\n",
    "    pdf = pyPdf.PdfFileReader(open(str(path),\"rb\"))\n",
    "    stopword_list = list(stopwords.words(\"english\"))\n",
    "\n",
    "    # read PDF file in a list\n",
    "    pdf_content = []\n",
    "    for page in pdf.pages:\n",
    "        pdf_content.append(page.extractText())\n",
    "\n",
    "    # tokenize all the words in the resume\n",
    "    tokenize = []\n",
    "    for line in pdf_content:\n",
    "        tokenize = filter(None,(line.split(\" \")))\n",
    "\n",
    "    # remove punctuations and case-fold\n",
    "    no_punctuations = []\n",
    "    for token in tokenize:\n",
    "        no_punctuations.append(token.rstrip(\",:|.-\").lower())\n",
    "\n",
    "    # remove stop words\n",
    "    without_stop_words = []\n",
    "\n",
    "    for word in filter(None, no_punctuations):\n",
    "        if word not in stopword_list:\n",
    "            without_stop_words.append(word)\n",
    "\n",
    "    return without_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "'''\n",
    "Using the following formula to calculate BM25\n",
    "((k3 + 1)q)/((k3 + q)) * ((k1 + 1)f)/((K + f)) * log((r + 0.5)(N − n − R + r + 0.5))/((n − r + 0.5)(R − r + 0.5))\n",
    "REFERENCE: https://xapian.org/docs/bm25.html\n",
    "'''\n",
    "\n",
    "# DEFINING CONSTANTS\n",
    "\n",
    "k1 = 1.2\n",
    "b = 0.75\n",
    "k2 = 100\n",
    "R = 0 #Since no relevance info is available\n",
    "\n",
    "# MAIN METHOD\n",
    "def BM25(docLen, avDocLen, n, N, f, q, r):\n",
    "    p1 = ((k2 + 1) * q) / (k2 + q)\n",
    "    p2 = ((k1 + 1) * f) / (getK(docLen, avDocLen) + f)\n",
    "    p3 = log((r + 0.5) * (N - n - R + r + 0.5)) / ((n - r + 0.5) * (R - r + 0.5))\n",
    "    return p1 * p2 * p3\n",
    "\n",
    "def getK(docLen, avDocLen):\n",
    "    return k1 * ((1 - b) + b * (float(docLen) / float(avDocLen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "#from retrieval import BM25\n",
    "\n",
    "# get average document length\n",
    "def get_avdl(length_index):\n",
    "    corpus_length = 0\n",
    "    for document in length_index:\n",
    "        corpus_length += length_index[document]\n",
    "    return float(corpus_length) / float(len(length_index))\n",
    "\n",
    "def search(query):\n",
    "    inv_index_file = open(\"D:/Kuliah/Semester 8/ISS4011    Sistem Temu Balik Informasi/Project INRE/Project INRE/dependency/indexes/inverted_index.json\",\"r\")\n",
    "    inverted_index = json.load(inv_index_file)\n",
    "\n",
    "    length_index_file = open(\"D:/Kuliah/Semester 8/ISS4011    Sistem Temu Balik Informasi/Project INRE/Project INRE/dependency/indexes/length_index.json\",\"r\")\n",
    "    length_index = json.load(length_index_file)\n",
    "\n",
    "    scores = defaultdict(list)\n",
    "    query_tokens = query.split()\n",
    "    for token in query_tokens:\n",
    "        for entry in inverted_index[token]:\n",
    "            scores[entry[0]] = BM25(length_index[entry[0]],get_avdl(length_index),len(inverted_index[token]),len(length_index),entry[1],1,0)\n",
    "    return sorted(scores.items(),key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import glob\n",
    "import json\n",
    "\n",
    "\n",
    "def get_file_names():\n",
    "    files = []\n",
    "    for file in glob.glob(\"D:/Kuliah/Semester 8/ISS4011    Sistem Temu Balik Informasi/Project INRE/Project INRE/dependency/documents/*.pdf\"):\n",
    "        files.append(file)\n",
    "    return files\n",
    "\n",
    "\n",
    "def make_index(tokens, document_name, index, length):\n",
    "    for term in set(tokens):\n",
    "        index[term].append([document_name,tokens.count(term)])\n",
    "        length[document_name] = len(set(tokens))\n",
    "\n",
    "\n",
    "def generator():\n",
    "    files = get_file_names()\n",
    "    inverted_index = defaultdict(list)\n",
    "    length_index = defaultdict(list)\n",
    "    for file in files:\n",
    "        make_index(tokenize(file), file, inverted_index, length_index)\n",
    "    write(inverted_index,length_index)\n",
    "    print \"Indexes generated\"\n",
    "\n",
    "\n",
    "def write(inverted_index,length_index):\n",
    "    inv_index_file = open(\"D:/Kuliah/Semester 8/ISS4011    Sistem Temu Balik Informasi/Project INRE/Project INRE/dependency/indexes/inverted_index.json\",\"w\")\n",
    "    json.dump(inverted_index,inv_index_file)\n",
    "\n",
    "    length_index_file = open(\"D:/Kuliah/Semester 8/ISS4011    Sistem Temu Balik Informasi/Project INRE/Project INRE/dependency/indexes/length_index.json\",\"w\")\n",
    "    json.dump(length_index,length_index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes generated\n",
      "\n",
      "\n",
      "Enter search query\n",
      ":: algoritma\n",
      "\n",
      "The Matching Files Are:\n",
      "D:/Kuliah/Semester 8/ISS4011    Sistem Temu Balik Informasi/Project INRE/Project INRE/dependency/documents\\3125-8157-1-PB.pdf\n",
      "D:/Kuliah/Semester 8/ISS4011    Sistem Temu Balik Informasi/Project INRE/Project INRE/dependency/documents\\2494-1-17516-1-10-20180212.pdf\n",
      "D:/Kuliah/Semester 8/ISS4011    Sistem Temu Balik Informasi/Project INRE/Project INRE/dependency/documents\\567-1195-1-PB.pdf\n",
      "\n",
      "\n",
      "Enter search query\n"
     ]
    }
   ],
   "source": [
    "generator()\n",
    "option = \"\"\n",
    "while option != \"q\":\n",
    "    print \"\\n\"\n",
    "    print \"Enter search query\"\n",
    "    keywords = raw_input(\":: \")\n",
    "    results = search(keywords)\n",
    "    print\"\\nThe Matching Files Are:\"\n",
    "    for result in results:\n",
    "        print result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
